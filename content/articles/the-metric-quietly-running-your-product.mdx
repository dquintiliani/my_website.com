---
title: "The Metric That's Quietly Running Your Product"
date: "2025-07-04"
excerpt: "Every product team has a north star metric. Most teams also have a shadow metric — an unofficial number that actually drives decisions. Naming it is the first step to managing it."
tags: ["Data Analytics", "Decision Science", "Product Management"]
readTime: "6"
slug: "the-metric-quietly-running-your-product"
---

## Every Team Has a Shadow Metric

Ask a product team what they're optimising for and they'll tell you their north star. Ask them what number actually makes or breaks their quarterly review, and you'll often get a different answer.

The shadow metric is real, it's powerful, and it almost always creates problems — not because measurement is bad, but because *unmeasured measurement* is. When a number drives behaviour without being officially acknowledged, it can't be interrogated, contested, or improved.

## How Shadow Metrics Form

They usually start innocently. The north star is hard to move in the short term, so the team picks a proxy that's more responsive. Sessions, signups, activation rates — whatever is measurable and improvable within a sprint cycle.

The proxy becomes the thing people optimise for. It gets discussed in standups. It gets celebrated when it goes up. Slowly, it starts to function as the real north star — but without any of the scrutiny that the official north star received.

The proxy is almost always easier to move than the underlying outcome. That's why it was chosen. It's also why it's dangerous.

## The Proxy Trap in Practice

A few patterns worth recognising:

**Optimising signups at the cost of activation.** You can almost always get more signups by lowering friction in the signup flow — but if the users signing up aren't the right ones, you've grown a leaky bucket. The shadow metric (signups) looked great right up until retention numbers collapsed.

**Chasing engagement for its own sake.** Time-on-site and page views are seductive because they're responsive to almost anything you ship. But engagement without a clear theory of how it connects to value creation is just noise. Teams that chase engagement often build features users interact with but don't pay for.

**Revenue without margin awareness.** Enterprise teams sometimes celebrate bookings that require so much professional services support that they're negative margin. The shadow metric (revenue) was moving; the real outcome (profitable growth) wasn't.

## What to Do About It

You can't eliminate proxies — you need them. The goal isn't purity; it's transparency.

**Name the shadow metric explicitly.** Put it on your dashboard next to the north star. Give it a name. The moment it's visible, it can be questioned.

**Define the relationship you expect.** If you're using activation rate as a proxy for long-term retention, write down your hypothesis: "We believe that users who complete onboarding within 7 days will have 60-day retention that is 2x users who don't." Now you can test whether the proxy is actually predictive.

**Set degradation alerts, not just improvement targets.** If your proxy improves but your north star stagnates or declines for two consecutive periods, something is wrong. Build that check into your review cadence before it becomes a pattern.

## The Bigger Point

Metrics shape behaviour. That's the whole point of having them. But metrics that shape behaviour without being clearly chosen and openly examined will eventually take your team somewhere you didn't intend to go.

The most analytically rigorous teams I've worked with are rigorous not because they have better data — they have better conversations about what the data means. That starts with being willing to name the number that's actually running the show.